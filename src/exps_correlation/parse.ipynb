{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 69 entries to aiden.csv\n"
     ]
    }
   ],
   "source": [
    "# serialize_leaderboard.py\n",
    "import csv\n",
    "\n",
    "input_file = \"raw_data/aiden.txt\"   # your raw input file\n",
    "output_file = \"cleaned_data/aiden.csv\"\n",
    "\n",
    "records = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) >= 2:\n",
    "            model = parts[0].strip()\n",
    "            acc = parts[1].strip().replace(\"%\", \"\")  # remove % sign\n",
    "            try:\n",
    "                acc_val = float(acc)\n",
    "            except ValueError:\n",
    "                continue  # skip if not a number\n",
    "            records.append((model, acc_val))\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Model\", \"Accuracy\"])\n",
    "    writer.writerows(records)\n",
    "\n",
    "print(f\"Serialized {len(records)} entries to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-parse using flexible splitting: first two columns are Model and Organization,\n",
    "# the rest are numeric. We'll join Model and Organization carefully.\n",
    "\n",
    "with open(\"raw_data/livebench.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "rows = []\n",
    "for line in raw_text.strip().split(\"\\n\"):\n",
    "    if line.startswith(\"Model\") or not line.strip():\n",
    "        continue\n",
    "    parts = line.split(\"\\t\")\n",
    "    if len(parts) < 5:\n",
    "        continue\n",
    "    \n",
    "    model = parts[0].strip()\n",
    "    coding_avg = parts[3].strip()  # 0=Model, 1=Org, 2=Global, 3=Reasoning, 4=Coding...\n",
    "    \n",
    "    # Actually coding average is the 4th column after Organization, i.e. index 4\n",
    "    # Fix:\n",
    "    try:\n",
    "        coding_avg = parts[4].strip()\n",
    "    except:\n",
    "        coding_avg = \"\"\n",
    "    \n",
    "    rows.append([model, coding_avg])\n",
    "\n",
    "# Create DataFrame\n",
    "df_clean = pd.DataFrame(rows, columns=[\"Model\", \"Coding-Average\"])\n",
    "\n",
    "# Save preview\n",
    "csv_output_clean = df_clean.to_csv('output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Paste your text file content into raw_text\n",
    "with open(\"raw_data/berkeley.txt\", 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Read tab-separated file\n",
    "df = pd.read_csv(StringIO(raw_text), sep=\"\\t\")\n",
    "\n",
    "# Average the 2nd and 3rd Overall Acc columns (index 4 and 5 in this layout)\n",
    "df[\"Overall_Acc_Avg_2_3\"] = df.iloc[:, 5:7].mean(axis=1)\n",
    "\n",
    "# Select useful columns\n",
    "df_out = df[[\"Model\", \"Overall_Acc_Avg_2_3\"]]\n",
    "\n",
    "# Save to CSV (string or file)\n",
    "df_out.to_csv(\"cleaned_data/berkeley.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed MCPMark CSV to cleaned_data/mcpmark.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "input_file = \"raw_data/mcpmark.txt\"\n",
    "output_file = \"cleaned_data/mcpmark.csv\"\n",
    "\n",
    "# Regex pattern to split on 2+ spaces\n",
    "split_pattern = re.compile(r\"\\s{2,}\")\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Skip headers and dashed lines\n",
    "data_lines = [line.strip() for line in lines if line.strip() and not set(line.strip()) <= {\"-\"}]\n",
    "\n",
    "# First line is header\n",
    "header = split_pattern.split(data_lines[0])\n",
    "\n",
    "rows = []\n",
    "for line in data_lines[1:]:\n",
    "    fields = split_pattern.split(line)\n",
    "\n",
    "    # Ensure length >= header\n",
    "    if len(fields) < len(header):\n",
    "        continue\n",
    "\n",
    "    # Extract model, version, pass@1\n",
    "    model = fields[1]\n",
    "    version = fields[2]\n",
    "\n",
    "    # Extract numeric Pass@1 (remove \"Â± std\" and \"%\")\n",
    "    pass1_raw = fields[3]\n",
    "    match = re.search(r\"([\\d.]+)\", pass1_raw)\n",
    "    pass1_val = float(match.group(1)) if match else None\n",
    "\n",
    "    rows.append([model, version, pass1_val])\n",
    "\n",
    "# Write output\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Model\", \"Version\", \"Pass@1\"])\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved parsed MCPMark CSV to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
