cpu-bind=MASK - nlpgpu08, task  0  0 [14913]: mask 0x100000001 set
2025-12-05 15:52:28,607 - INFO - Making Dataset
2025-12-05 15:52:31,675 - INFO - Running Arm2
2025-12-05 15:52:32,070 - INFO - Running batches for sim
  0%|          | 0/204 [00:00<?, ?it/s]2025-12-05 15:52:32,745 - INFO - Retrying request to /chat/completions in 0.394447 seconds
2025-12-05 15:52:33,141 - INFO - Retrying request to /chat/completions in 0.810511 seconds
Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/lcars/home/t/tongt1/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 982, in request
    response = self._client.send(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/lcars/home/t/tongt1/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/main.py", line 163, in <module>
    run(args)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/main.py", line 49, in run
    _, data = arm2.run()
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/arms.py", line 79, in run
    answers = run_batch(messages, self.default_args, self.client)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 302, in run_batch
    return [client.chat(args.model, m, max_tokens=args.max_tokens, temperature=0.0, top_p=1.0, stop=None) for m in tqdm(messages_list)]
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 302, in <listcomp>
    return [client.chat(args.model, m, max_tokens=args.max_tokens, temperature=0.0, top_p=1.0, stop=None) for m in tqdm(messages_list)]
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 100, in chat
    resp = self.client.chat.completions.create(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1147, in create
    return self._post(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
  0%|          | 0/204 [00:02<?, ?it/s]
2025-12-05 15:52:53,085 - INFO - Making Dataset
2025-12-05 15:52:53,924 - INFO - Running Arm2
2025-12-05 15:52:54,310 - INFO - Running batches for sim
  0%|          | 0/204 [00:00<?, ?it/s]2025-12-05 15:52:54,606 - INFO - Retrying request to /chat/completions in 0.394447 seconds
2025-12-05 15:52:55,003 - INFO - Retrying request to /chat/completions in 0.810511 seconds
Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "/lcars/home/t/tongt1/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 982, in request
    response = self._client.send(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/lcars/home/t/tongt1/.local/share/uv/python/cpython-3.10.18-linux-x86_64-gnu/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/main.py", line 163, in <module>
    run(args)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/main.py", line 49, in run
    _, data = arm2.run()
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/arms.py", line 79, in run
    answers = run_batch(messages, self.default_args, self.client)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 302, in run_batch
    return [client.chat(args.model, m, max_tokens=args.max_tokens, temperature=0.0, top_p=1.0, stop=None) for m in tqdm(messages_list)]
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 302, in <listcomp>
    return [client.chat(args.model, m, max_tokens=args.max_tokens, temperature=0.0, top_p=1.0, stop=None) for m in tqdm(messages_list)]
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/src/exps_performance/llm.py", line 100, in chat
    resp = self.client.chat.completions.create(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", line 1147, in create
    return self._post(
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/mnt/nlpgpu-io1/data/terry/ToolProj/.venv/lib/python3.10/site-packages/openai/_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
  0%|          | 0/204 [00:01<?, ?it/s]
